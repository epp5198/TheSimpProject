import requests
from bs4 import BeautifulSoup
import os
import re

url = 'https://subslikescript.com/series/MASH-68098'

# Make request
response = requests.get(url)

# Parse content
soup = BeautifulSoup(response.content, 'html.parser')

# Create directory for scripts
if not os.path.exists('MASH'):
    os.makedirs('MASH')

# Find all season containers
season_containers = soup.select('div.season, div.season.wide')
if not season_containers:
    print('Could not find seasons')
    exit()

# Loop through season containers
for season_container in season_containers:
    # Get season number
    season_number = re.search(r'Season (\d+)', season_container.find('h4').text.strip()).group(1)

    # Create directory for season
    season_dir = os.path.join('MASH', f'Season {season_number}')
    if not os.path.exists(season_dir):
        os.makedirs(season_dir)

    # Get all episode links for the season
    episode_links = season_container.find_all('a', href=True)

    # Loop through episode links
    for episode_link in episode_links:
        # Get episode title
        episode_title = episode_link.text.strip()

        # Create file name
        file_name = re.sub(r'\W+', '', episode_title) + '.txt'

        # Make request to episode page
        episode_url = f"https://subslikescript.com{episode_link['href']}"
        episode_response = requests.get(episode_url)
        episode_soup = BeautifulSoup(episode_response.content, 'html.parser')

        # Find script container and extract script
        script_container = episode_soup.find('div', class_='full-script')
        if not script_container:
            print(f"No script found for {episode_title}")
            continue

        script_text = script_container.text.strip()

        # Write script to file
        file_path = os.path.join(season_dir, file_name)
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(script_text)

print('Done!')
